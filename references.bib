
@misc{zhang_practices_2023,
	title = {Practices and {Challenges} of {Using} {GitHub} {Copilot}: {An} {Empirical} {Study}},
	shorttitle = {Practices and {Challenges} of {Using} {GitHub} {Copilot}},
	url = {http://arxiv.org/abs/2303.08733},
	doi = {10.48550/arXiv.2303.08733},
	abstract = {With the advances in machine learning, there is a growing interest in AI-enabled tools for autocompleting source code. GitHub Copilot, also referred to as the "AI Pair Programmer", has been trained on billions of lines of open source GitHub code, and is one of such tools that has been increasingly used since its launch on June 2021. However, little effort has been devoted to understanding the practices and challenges of using Copilot in programming with auto-completed source code. To this end, we conducted an empirical study by collecting and analyzing the data from Stack Overflow (SO) and GitHub Discussions. More specifically, we searched and manually collected 169 SO posts and 655 GitHub discussions related to the usage of Copilot. We identified the programming languages, IDEs, technologies used with Copilot, functions implemented, benefits, limitations, and challenges when using Copilot. The results show that when practitioners use Copilot: (1) The major programming languages used with Copilot are JavaScript and Python, (2) the main IDE used with Copilot is Visual Studio Code, (3) the most common used technology with Copilot is Node.js, (4) the leading function implemented by Copilot is data processing, (5) the significant benefit of using Copilot is useful code generation, and (6) the main limitation encountered by practitioners when using Copilot is difficulty of integration. Our results suggest that using Copilot is like a double-edged sword, which requires developers to carefully consider various aspects when deciding whether or not to use it. Our study provides empirically grounded foundations and basis for future research on the role of Copilot as an AI pair programmer in software development.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Zhang, Beiqi and Liang, Peng and Zhou, Xiyu and Ahmad, Aakash and Waseem, Muhammad},
	month = apr,
	year = {2023},
	note = {arXiv:2303.08733},
	keywords = {Computer Science - Software Engineering},
}

@incollection{lieberman_feasibility_2006,
	address = {Dordrecht},
	title = {Feasibility {Studies} for {Programming} in {Natural} {Language}},
	isbn = {9781402053863},
	url = {https://doi.org/10.1007/1-4020-5386-X_20},
	abstract = {We think it is time to take another look at an old dream—that one could program a computer by speaking to it in natural language. Programming in natural language might seem impossible, because it would appear to require complete natural language understanding and dealing with the vagueness of human descriptions of programs. Butwe think that several developments might nowmake programming in natural language feasible. First, improved broad coverage natural language parsers and semantic extraction techniques permit partial understanding. Second, mixed-initiative dialogues can be used for meaning disambiguation. And finally, where direct understanding techniques fail, we hope to fall back on Programming by Example, and other techniques for specifying the program in a more fail-soft manner. To assess the feasibility of this project, as a first step, we are studying how non-programming users describe programs in unconstrained natural language.We are exploring how to design dialogs that help the user make precise their intentions for the program, while constraining them as little as possible.},
	language = {en},
	urldate = {2024-12-29},
	booktitle = {End {User} {Development}},
	publisher = {Springer Netherlands},
	author = {Lieberman, Henry and Liu, Hugo},
	editor = {Lieberman, Henry and Paternò, Fabio and Wulf, Volker},
	year = {2006},
	doi = {10.1007/1-4020-5386-X_20},
	pages = {459--473},
}

@inproceedings{ballard_programming_1979,
	address = {Not Known},
	title = {Programming in natural language: “{NLC}” as a prototype},
	isbn = {9780897910088},
	shorttitle = {Programming in natural language},
	url = {http://portal.acm.org/citation.cfm?doid=800177.810072},
	doi = {10.1145/800177.810072},
	language = {en},
	urldate = {2024-12-29},
	booktitle = {Proceedings of the 1979 annual conference on   - {ACM} 79},
	publisher = {ACM Press},
	author = {Ballard, Bruce W. and Biermann, Alan W.},
	year = {1979},
	pages = {228--237},
}

@inproceedings{mihalcea_nlp_2006,
	address = {Berlin, Heidelberg},
	title = {{NLP} ({Natural} {Language} {Processing}) for {NLP} ({Natural} {Language} {Programming})},
	isbn = {9783540322061},
	doi = {10.1007/11671299_34},
	abstract = {Natural Language Processing holds great promise for making computer interfaces that are easier to use for people, since people will (hopefully) be able to talk to the computer in their own language, rather than learn a specialized language of computer commands. For programming, however, the necessity of a formal programming language for communicating with a computer has always been taken for granted. We would like to challenge this assumption. We believe that modern Natural Language Processing techniques can make possible the use of natural language to (at least partially) express programming ideas, thus drastically increasing the accessibility of programming to non-expert users. To demonstrate the feasibility of Natural Language Programming, this paper tackles what are perceived to be some of the hardest cases: steps and loops. We look at a corpus of English descriptions used as programming assignments, and develop some techniques for mapping linguistic constructs onto program structures, which we refer to as programmatic semantics.},
	language = {en},
	booktitle = {Computational {Linguistics} and {Intelligent} {Text} {Processing}},
	publisher = {Springer},
	author = {Mihalcea, Rada and Liu, Hugo and Lieberman, Henry},
	editor = {Gelbukh, Alexander},
	year = {2006},
	pages = {319--330},
}

@article{miller_natural_1981,
	title = {Natural language programming: {Styles}, strategies, and contrasts},
	volume = {20},
	issn = {0018-8670},
	shorttitle = {Natural language programming},
	url = {https://ieeexplore.ieee.org/abstract/document/5387906},
	doi = {10.1147/sj.202.0184},
	abstract = {Our objective in this study was to obtain detailed empirical information about the nature of natural language “programming” to bring to bear on the issueosf increasing the usability of computer language interfaces. Although we expected numerous difficulties to be detected concerning the potentioalf actually implementing a system to interpret natural language programs, we were not prepared for the magnitude of what we see as being the three major obstacles: style, semantics, and world knowledge. Concerning the first, there is little way in which the vast differences in styles could be increased: programming-language style is simply alien to natural specification. With respect to semantics, we also were unprepared to find out the extent to which the selection of the appropriate “meaning” (to a word, phrase, or sentence) is dependent upon the immediate and prior context. And as for world nowledge, we suspect that the extent to which shared experiences and knowledge are critical to procedural communication and understanding among people has barely been hintaetd by our present data.},
	number = {2},
	urldate = {2024-12-29},
	journal = {IBM Systems Journal},
	author = {Miller, L. A.},
	year = {1981},
	pages = {184--215},
}

@inproceedings{vadaparty_cs1-llm_2024,
	address = {Milan Italy},
	title = {{CS1}-{LLM}: {Integrating} {LLMs} into {CS1} {Instruction}},
	isbn = {9798400706004},
	shorttitle = {{CS1}-{LLM}},
	url = {https://dl.acm.org/doi/10.1145/3649217.3653584},
	doi = {10.1145/3649217.3653584},
	language = {en},
	urldate = {2024-12-29},
	booktitle = {Proceedings of the 2024 on {Innovation} and {Technology} in {Computer} {Science} {Education} {V}. 1},
	publisher = {ACM},
	author = {Vadaparty, Annapurna and Zingaro, Daniel and Smith Iv, David H. and Padala, Mounika and Alvarado, Christine and Gorson Benario, Jamie and Porter, Leo},
	month = jul,
	year = {2024},
	pages = {297--303},
}

@inproceedings{halpern_foundations_1966,
	address = {San Francisco, California},
	title = {Foundations of the case for natural-language programming},
	url = {http://portal.acm.org/citation.cfm?doid=1464291.1464360},
	doi = {10.1145/1464291.1464360},
	language = {en},
	urldate = {2024-12-29},
	booktitle = {Proceedings of the {November} 7-10, 1966, fall joint computer conference on {XX} - {AFIPS} '66 ({Fall})},
	publisher = {ACM Press},
	author = {Halpern, Mark},
	year = {1966},
	pages = {639},
}

@article{sammet_use_1966,
	title = {The use of {English} as a programming language},
	volume = {9},
	issn = {0001-0782},
	url = {https://dl.acm.org/doi/10.1145/365230.365274},
	doi = {10.1145/365230.365274},
	abstract = {The purpose of this talk is to make a personal plea, backed up by some practical comments, for the use of English or anyone else's natural language as a programming language. This seems to be a suitable subject for the conference, since whatever definition of pragmatics is decided upon, it certainly seems to be tied in with the users of any programming language and what the language means to them.},
	number = {3},
	urldate = {2024-12-29},
	journal = {Commun. ACM},
	author = {Sammet, Jean E.},
	month = mar,
	year = {1966},
	pages = {228--230},
}

@incollection{bauer_foolishness_1979,
	address = {Berlin, Heidelberg},
	title = {On the foolishness of “natural language programming”},
	volume = {69},
	isbn = {9783540092513 9783540353126},
	url = {https://link.springer.com/10.1007/BFb0014656},
	language = {en},
	urldate = {2024-12-29},
	booktitle = {Program {Construction}},
	publisher = {Springer Berlin Heidelberg},
	author = {Dijkstra, Edsger W.},
	editor = {Bauer, Friedrich L. and Broy, Manfred and Dijkstra, E. W. and Gerhart, S. L. and Gries, D. and Griffiths, M. and Guttag, J. V. and Horning, J. J. and Owicki, S. S. and Pair, C. and Partsch, H. and Pepper, P. and Wirsing, M. and Wössner, H.},
	year = {1979},
	doi = {10.1007/BFb0014656},
	pages = {51--53},
}

@article{gulwani_program_2017,
	title = {Program {Synthesis}},
	volume = {4},
	issn = {2325-1107, 2325-1131},
	url = {https://www.nowpublishers.com/article/Details/PGL-010},
	doi = {10.1561/2500000010},
	abstract = {Program Synthesis},
	language = {English},
	number = {1-2},
	urldate = {2024-12-29},
	journal = {Foundations and Trends® in Programming Languages},
	author = {Gulwani, Sumit and Polozov, Oleksandr and Singh, Rishabh},
	month = jul,
	year = {2017},
	pages = {1--119},
}

@misc{prather_beyond_2024,
	title = {Beyond the {Hype}: {A} {Comprehensive} {Review} of {Current} {Trends} in {Generative} {AI} {Research}, {Teaching} {Practices}, and {Tools}},
	shorttitle = {Beyond the {Hype}},
	url = {http://arxiv.org/abs/2412.14732},
	doi = {10.48550/arXiv.2412.14732},
	abstract = {Generative AI (GenAI) is advancing rapidly, and the literature in computing education is expanding almost as quickly. Initial responses to GenAI tools were mixed between panic and utopian optimism. Many were fast to point out the opportunities and challenges of GenAI. Researchers reported that these new tools are capable of solving most introductory programming tasks and are causing disruptions throughout the curriculum. These tools can write and explain code, enhance error messages, create resources for instructors, and even provide feedback and help for students like a traditional teaching assistant. In 2024, new research started to emerge on the effects of GenAI usage in the computing classroom. These new data involve the use of GenAI to support classroom instruction at scale and to teach students how to code with GenAI. In support of the former, a new class of tools is emerging that can provide personalized feedback to students on their programming assignments or teach both programming and prompting skills at the same time. With the literature expanding so rapidly, this report aims to summarize and explain what is happening on the ground in computing classrooms. We provide a systematic literature review; a survey of educators and industry professionals; and interviews with educators using GenAI in their courses, educators studying GenAI, and researchers who create GenAI tools to support computing education. The triangulation of these methods and data sources expands the understanding of GenAI usage and perceptions at this critical moment for our community.},
	urldate = {2024-12-29},
	publisher = {arXiv},
	author = {Prather, James and Leinonen, Juho and Kiesler, Natalie and Benario, Jamie Gorson and Lau, Sam and MacNeil, Stephen and Norouzi, Narges and Opel, Simone and Pettit, Vee and Porter, Leo and Reeves, Brent N. and Savelka, Jaromir and IV, David H. Smith and Strickroth, Sven and Zingaro, Daniel},
	month = dec,
	year = {2024},
	note = {arXiv:2412.14732},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computers and Society, Computer Science - Human-Computer Interaction, Computer Science - Software Engineering},
}

@inproceedings{becker_programming_2023,
	address = {New York, NY, USA},
	series = {{SIGCSE} 2023},
	title = {Programming {Is} {Hard} - {Or} at {Least} {It} {Used} to {Be}: {Educational} {Opportunities} and {Challenges} of {AI} {Code} {Generation}},
	isbn = {9781450394314},
	shorttitle = {Programming {Is} {Hard} - {Or} at {Least} {It} {Used} to {Be}},
	url = {https://dl.acm.org/doi/10.1145/3545945.3569759},
	doi = {10.1145/3545945.3569759},
	abstract = {The introductory programming sequence has been the focus of much research in computing education. The recent advent of several viable and freely-available AI-driven code generation tools present several immediate opportunities and challenges in this domain. In this position paper we argue that the community needs to act quickly in deciding what possible opportunities can and should be leveraged and how, while also working on overcoming otherwise mitigating the possible challenges. Assuming that the effectiveness and proliferation of these tools will continue to progress rapidly, without quick, deliberate, and concerted efforts, educators will lose advantage in helping shape what opportunities come to be, and what challenges will endure. With this paper we aim to seed this discussion within the computing education community.},
	urldate = {2024-12-29},
	booktitle = {Proceedings of the 54th {ACM} {Technical} {Symposium} on {Computer} {Science} {Education} {V}. 1},
	publisher = {Association for Computing Machinery},
	author = {Becker, Brett A. and Denny, Paul and Finnie-Ansley, James and Luxton-Reilly, Andrew and Prather, James and Santos, Eddie Antonio},
	month = mar,
	year = {2023},
	pages = {500--506},
}

@article{poplack_sometimes_1980,
	title = {Sometimes {I}’ll start a sentence in {Spanish} {Y} {TERMINO} {EN} {ESPAÑOL}: toward a typology of code-switching1},
	volume = {18},
	copyright = {De Gruyter expressly reserves the right to use all content for commercial text and data mining within the meaning of Section 44b of the German Copyright Act.},
	issn = {1613-396X},
	shorttitle = {Sometimes {I}’ll start a sentence in {Spanish} {Y} {TERMINO} {EN} {ESPAÑOL}},
	url = {https://www.degruyter.com/document/doi/10.1515/ling.1980.18.7-8.581/html},
	doi = {10.1515/ling.1980.18.7-8.581},
	abstract = {Article Sometimes I’ll start a sentence in Spanish Y TERMINO EN ESPAÑOL: toward a typology of code-switching1 was published on January 1, 1980 in the journal Linguistics (volume 18, issue 7-8).},
	language = {en},
	number = {7-8},
	urldate = {2024-12-29},
	author = {Poplack, Shana},
	month = jan,
	year = {1980},
	pages = {581--618},
}

@incollection{heller_8_1988,
	title = {8. {Contrasting} patterns of codeswitching in two communities},
	isbn = {9783110113761},
	url = {https://www.degruyter.com/document/doi/10.1515/9783110849615.215/html},
	urldate = {2024-12-28},
	booktitle = {Codeswitching},
	publisher = {De Gruyter Mouton},
	author = {Poplack, Shana},
	editor = {Heller, Monica},
	month = may,
	year = {1988},
	doi = {10.1515/9783110849615.215},
	pages = {215--244},
}

@article{pfaff_constraints_1979,
	title = {Constraints on {Language} {Mixing}: {Intrasentential} {Code}-{Switching} and {Borrowing} in {Spanish}/{English}},
	volume = {55},
	issn = {0097-8507},
	shorttitle = {Constraints on {Language} {Mixing}},
	url = {https://www.jstor.org/stable/412586},
	doi = {10.2307/412586},
	abstract = {Mixture of Spanish and English, whether in isolated loan words or in code-switching of clauses and sentences, while socially motivated, is subject to clear linguistic constraints. Quantitative analysis of mixing in conversations of Mexican-Americans suggests specific functional constraints to express tense/aspect/mood and subject/object relationships, as well as structural constraints which permit only surface structures which are grammatical in both languages. Resolution of structural conflict plays a key role, so that lexical cores trigger longer phrasal switches if they govern rules which create non-shared surface structures. The relative frequency of mixes without structural conflict is constrained by discourse function.},
	number = {2},
	urldate = {2024-12-28},
	journal = {Language},
	author = {Pfaff, Carol W.},
	year = {1979},
	pages = {291--318},
}

@article{zentella_integrating_1990,
	title = {Integrating {Qualitative} and {Quantitative} {Methods} in the {Study} of {Bilingual} {Code} {Switching}},
	volume = {583},
	copyright = {http://onlinelibrary.wiley.com/termsAndConditions\#vor},
	issn = {0077-8923, 1749-6632},
	url = {https://nyaspubs.onlinelibrary.wiley.com/doi/10.1111/j.1749-6632.1990.tb12186.x},
	doi = {10.1111/j.1749-6632.1990.tb12186.x},
	language = {en},
	number = {1},
	urldate = {2024-12-28},
	journal = {Annals of the New York Academy of Sciences},
	author = {Zentella, Ana Celia},
	month = may,
	year = {1990},
	pages = {75--92},
}

@book{jacobson_codeswitching_1998,
	title = {Codeswitching {Worldwide}, {Bd}. {I}:},
	isbn = {9783110151510},
	shorttitle = {Codeswitching {Worldwide}, {Bd}. {I}},
	url = {https://www.degruyter.com/document/doi/10.1515/9783110812190/html},
	urldate = {2024-12-28},
	publisher = {DE GRUYTER MOUTON},
	editor = {Jacobson, Rodolfo},
	month = dec,
	year = {1998},
	doi = {10.1515/9783110812190},
}

@article{berk-seligson_linguistic_1986,
	title = {Linguistic constraints on intrasentential code-switching: {A} study of {Spanish}/{Hebrew} bilingualism},
	volume = {15},
	copyright = {https://www.cambridge.org/core/terms},
	issn = {0047-4045, 1469-8013},
	shorttitle = {Linguistic constraints on intrasentential code-switching},
	url = {https://www.cambridge.org/core/product/identifier/S0047404500011799/type/journal_article},
	doi = {10.1017/S0047404500011799},
	abstract = {ABSTRACT 
            In recent years, research has increasingly pointed toward the universality of three linguistic constraints on code-switching: (1) an equivalence of structure constraint, (2) a size-of-constituent constraint, and (3) a free morpheme constraint. The evidence derived from this study challenges the universality of the first two of these constraints, and argues instead that their claim to universality is largely a function of the coincidental relative similarity in the syntactic structure of Spanish and English, the two languages upon which most code-switching studies have been based. The present study breaks out of the Spanish-English mold and draws upon data from a language contact situation in which the two languages are syntactically very different from each other, namely, Spanish and Hebrew. The evidence presented also challenges the frequently made assertion that type of code-switching, namely, intra- versus intersentential code-switching, is correlated with degree of bilingualism of the speaker. Finally, the evidence suggests that intrasentential code-switching ability cannot, as some have argued, universally be considered a measure of bilingualism nor a mark of the balanced bilingual. (Code-switching, Spanish, Hebrew, bilingualism, syntactic constraints)},
	language = {en},
	number = {3},
	urldate = {2024-12-28},
	journal = {Language in Society},
	author = {Berk-Seligson, Susan},
	month = sep,
	year = {1986},
	pages = {313--348},
}

@book{gardner-chloros_code-switching_2009,
	edition = {1},
	title = {Code-switching},
	copyright = {https://www.cambridge.org/core/terms},
	isbn = {9780521862646 9780521681131 9780511609787},
	url = {https://www.cambridge.org/core/product/identifier/9780511609787/type/book},
	abstract = {It is quite commonplace for bilingual speakers to use two or more languages, dialects or varieties in the same conversation, without any apparent effort. The phenomenon, known as code-switching, has become a major focus of attention in linguistics. This concise and original study explores how, when and where code-switching occurs. Drawing on a diverse range of examples from medieval manuscripts to rap music, novels to advertisements, emails to political speeches, and above all everyday conversation, it argues that code-switching can only be properly understood if we study it from a variety of perspectives. It shows how sociolinguistic, psycholinguistic, grammatical and developmental aspects of code-switching are all interdependent, and findings in each area are crucial to others. Breaking down barriers across the discipline of linguistics, this pioneering book confronts fundamental questions about what a 'native language' is, and whether languages can be meaningfully studied outside of the individuals who use them.},
	urldate = {2024-12-28},
	publisher = {Cambridge University Press},
	author = {Gardner-Chloros, Penelope},
	month = jun,
	year = {2009},
	doi = {10.1017/CBO9780511609787},
}

@inproceedings{jordan_need_2024,
	address = {New York, NY, USA},
	series = {{SIGCSE} 2024},
	title = {Need a {Programming} {Exercise} {Generated} in {Your} {Native} {Language}? {ChatGPT}'s {Got} {Your} {Back}: {Automatic} {Generation} of {Non}-{English} {Programming} {Exercises} {Using} {OpenAI} {GPT}-3.5},
	isbn = {9798400704239},
	shorttitle = {Need a {Programming} {Exercise} {Generated} in {Your} {Native} {Language}?},
	url = {https://dl.acm.org/doi/10.1145/3626252.3630897},
	doi = {10.1145/3626252.3630897},
	abstract = {Large language models (LLMs) like ChatGPT are changing computing education and may create additional barriers to those already faced by non-native English speakers (NNES) learning computing. We investigate an opportunity for a positive impact of LLMs on NNES through multilingual programming exercise generation. Following previous work with LLM exercise generation in English, we prompt OpenAI GPT-3.5 in 4 natural languages (English, Tamil, Spanish, and Vietnamese) to create introductory programming problems, sample solutions, and test cases. We evaluate these problems on their sensibility, readability, translation, sample solution accuracy, topicality, and cultural relevance. We find that problems generated in English, Spanish, and Vietnamese are largely sensible, easily understood, and accurate in their sample solutions. However, Tamil problems are mostly non-sensible and have a much lower passing test rate, indicating that the abilities of LLMs for problem generation are not generalizable across languages. Our analysis suggests that these problems could not be given verbatim to students, but with minimal effort, most errors can be fixed. We further discuss the benefits of these problems despite their flaws, and their opportunities to provide personalized and culturally relevant resources for students in their native languages.},
	urldate = {2024-12-28},
	booktitle = {Proceedings of the 55th {ACM} {Technical} {Symposium} on {Computer} {Science} {Education} {V}. 1},
	publisher = {Association for Computing Machinery},
	author = {Jordan, Mollie and Ly, Kevin and Soosai Raj, Adalbert Gerald},
	month = mar,
	year = {2024},
	pages = {618--624},
}

@article{ramesh_samanantar_2022,
	title = {\textit{{Samanantar}} : {The} {Largest} {Publicly} {Available} {Parallel} {Corpora} {Collection} for 11 {Indic} {Languages}},
	volume = {10},
	issn = {2307-387X},
	shorttitle = {\textit{{Samanantar}}},
	url = {https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00452/109468/Samanantar-The-Largest-Publicly-Available-Parallel},
	doi = {10.1162/tacl_a_00452},
	abstract = {Abstract 
            We present Samanantar, the largest publicly available parallel corpora collection for Indic languages. The collection contains a total of 49.7 million sentence pairs between English and 11 Indic languages (from two language families). Specifically, we compile 12.4 million sentence pairs from existing, publicly available parallel corpora, and additionally mine 37.4 million sentence pairs from the Web, resulting in a 4× increase. We mine the parallel sentences from the Web by combining many corpora, tools, and methods: (a) Web-crawled monolingual corpora, (b) document OCR for extracting sentences from scanned documents, (c) multilingual representation models for aligning sentences, and (d) approximate nearest neighbor search for searching in a large collection of sentences. Human evaluation of samples from the newly mined corpora validate the high quality of the parallel sentences across 11 languages. Further, we extract 83.4 million sentence pairs between all 55 Indic language pairs from the English-centric parallel corpus using English as the pivot language. We trained multilingual NMT models spanning all these languages on Samanantar which outperform existing models and baselines on publicly available benchmarks, such as FLORES, establishing the utility of Samanantar. Our data and models are available publicly at Samanantar and we hope they will help advance research in NMT and multilingual NLP for Indic languages.},
	language = {en},
	urldate = {2024-12-28},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Ramesh, Gowtham and Doddapaneni, Sumanth and Bheemaraj, Aravinth and Jobanputra, Mayank and Ak, Raghavan and Sharma, Ajitesh and Sahoo, Sujit and Diddee, Harshita and J, Mahalakshmi and Kakwani, Divyanshu and Kumar, Navneet and Pradeep, Aswin and Nagaraj, Srihari and Deepak, Kumar and Raghavan, Vivek and Kunchukuttan, Anoop and Kumar, Pratyush and Khapra, Mitesh Shantadevi},
	month = feb,
	year = {2022},
	pages = {145--162},
}

@article{bhattacharyya_indic_2019,
	title = {Indic language computing},
	volume = {62},
	issn = {0001-0782},
	url = {https://dl.acm.org/doi/10.1145/3343456},
	doi = {10.1145/3343456},
	number = {11},
	urldate = {2024-12-28},
	journal = {Commun. ACM},
	author = {Bhattacharyya, Pushpak and Murthy, Hema and Ranathunga, Surangika and Munasinghe, Ranjiva},
	month = oct,
	year = {2019},
	pages = {70--75},
}

@inproceedings{thara_code-mixing_2018,
	title = {Code-{Mixing}: {A} {Brief} {Survey}},
	shorttitle = {Code-{Mixing}},
	url = {https://ieeexplore.ieee.org/abstract/document/8554413/?casa_token=d5wnpY0XWVkAAAAA:CUp8C3YcgQEKzH79aMJgv6EHDqhwYQZWSOwMOj9kzROhySsEKV-tCCmKf-wRUmu5MbAmgwlv},
	doi = {10.1109/ICACCI.2018.8554413},
	abstract = {Indians and many other non-English speakers across the world, prefer not to use single code in their messaging texts on social media platforms. They make use of transliteration and randomly merged English words using code-mixing, two or more languages to show their linguistic proficiency (English-Spanish, Arabic-English, etc.). Code-mixing (CM) is a dynamically progressive area of research in the domain of text mining. Present time communications in social media, blogs, reviews are abuzz with creative, crafty code-mixed messages. This paper highlights a comprehensive study of CM in the diverse fields of Natural Language Processing (NLP) including language identification, Part-of-Speech (POS) tagging, Named Entity Recognition (NER), Polarity Identification, Question Answering. CM has also been sought after in studies involving Machine Translation, Dialect identification, Speech technologies etc. Most of the applications of code mixing are scrutinized and presented briefly in this survey. This study purports to articulate tends and, techniques pursued in languages used and also unique evaluation measures to give accuracy.},
	urldate = {2024-12-28},
	booktitle = {2018 {International} {Conference} on {Advances} in {Computing}, {Communications} and {Informatics} ({ICACCI})},
	author = {Thara, S and Poornachandran, Prabaharan},
	month = sep,
	year = {2018},
	keywords = {Adaboost, Feature extraction, Gaussian Naive Bayes, KNN, Logistic Regression, NER, Random Forest, SVM, Support vector machines, Switches, Tagging, Task analysis, Twitter, code mixed, feature vectors},
	pages = {2382--2388},
}

@misc{deroy_prompt_2024,
	title = {Prompt {Engineering} {Using} {GPT} for {Word}-{Level} {Code}-{Mixed} {Language} {Identification} in {Low}-{Resource} {Dravidian} {Languages}},
	url = {http://arxiv.org/abs/2411.04025},
	doi = {10.48550/arXiv.2411.04025},
	abstract = {Language Identification (LI) is crucial for various natural language processing tasks, serving as a foundational step in applications such as sentiment analysis, machine translation, and information retrieval. In multilingual societies like India, particularly among the youth engaging on social media, text often exhibits code-mixing, blending local languages with English at different linguistic levels. This phenomenon presents formidable challenges for LI systems, especially when languages intermingle within single words. Dravidian languages, prevalent in southern India, possess rich morphological structures yet suffer from under-representation in digital platforms, leading to the adoption of Roman or hybrid scripts for communication. This paper introduces a prompt based method for a shared task aimed at addressing word-level LI challenges in Dravidian languages. In this work, we leveraged GPT-3.5 Turbo to understand whether the large language models is able to correctly classify words into correct categories. Our findings show that the Kannada model consistently outperformed the Tamil model across most metrics, indicating a higher accuracy and reliability in identifying and categorizing Kannada language instances. In contrast, the Tamil model showed moderate performance, particularly needing improvement in precision and recall.},
	urldate = {2024-12-28},
	publisher = {arXiv},
	author = {Deroy, Aniket and Maity, Subhankar},
	month = nov,
	year = {2024},
	note = {arXiv:2411.04025},
	keywords = {Computer Science - Computation and Language},
}

@misc{yong_prompting_2023,
	title = {Prompting {Multilingual} {Large} {Language} {Models} to {Generate} {Code}-{Mixed} {Texts}: {The} {Case} of {South} {East} {Asian} {Languages}},
	shorttitle = {Prompting {Multilingual} {Large} {Language} {Models} to {Generate} {Code}-{Mixed} {Texts}},
	url = {http://arxiv.org/abs/2303.13592},
	doi = {10.48550/arXiv.2303.13592},
	abstract = {While code-mixing is a common linguistic practice in many parts of the world, collecting high-quality and low-cost code-mixed data remains a challenge for natural language processing (NLP) research. The recent proliferation of Large Language Models (LLMs) compels one to ask: how capable are these systems in generating code-mixed data? In this paper, we explore prompting multilingual LLMs in a zero-shot manner to generate code-mixed data for seven languages in South East Asia (SEA), namely Indonesian, Malay, Chinese, Tagalog, Vietnamese, Tamil, and Singlish. We find that publicly available multilingual instruction-tuned models such as BLOOMZ and Flan-T5-XXL are incapable of producing texts with phrases or clauses from different languages. ChatGPT exhibits inconsistent capabilities in generating code-mixed texts, wherein its performance varies depending on the prompt template and language pairing. For instance, ChatGPT generates fluent and natural Singlish texts (an English-based creole spoken in Singapore), but for English-Tamil language pair, the system mostly produces grammatically incorrect or semantically meaningless utterances. Furthermore, it may erroneously introduce languages not specified in the prompt. Based on our investigation, existing multilingual LLMs exhibit a wide range of proficiency in code-mixed data generation for SEA languages. As such, we advise against using LLMs in this context without extensive human checks.},
	urldate = {2024-12-28},
	publisher = {arXiv},
	author = {Yong, Zheng-Xin and Zhang, Ruochen and Forde, Jessica Zosa and Wang, Skyler and Subramonian, Arjun and Lovenia, Holy and Cahyawijaya, Samuel and Winata, Genta Indra and Sutawika, Lintang and Cruz, Jan Christian Blaise and Tan, Yin Lin and Phan, Long and Garcia, Rowena and Solorio, Thamar and Aji, Alham Fikri},
	month = sep,
	year = {2023},
	note = {arXiv:2303.13592},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language},
}
